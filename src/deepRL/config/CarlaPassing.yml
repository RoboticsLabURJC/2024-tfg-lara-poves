PPO:
  policy: "MultiInputPolicy"
  learning_rate: 0.0001
  gamma: 0.85
  gae_lambda: 0.8 # γ
  n_steps: 1024 # The number of steps to run for each environment per update
  batch_size: 512 # = n_steps * n_envs(=1)
  ent_coef: 0.3 # β
  clip_range: 0.2 # epsilon
  n_timesteps: 2_000_000
  
