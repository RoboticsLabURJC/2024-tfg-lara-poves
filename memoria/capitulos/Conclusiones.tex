\chapter{Conclusiones}
\label{cap:capitulo5}

En este TFG se han cumplido los objetivos marcados durante su desarrollo. Primero la creación de algoritmos de
navegación autónoma para drones para resolver la problemática de seguimiento de carril en entornos de carreteras. 
En segundo lugar la utilización de algoritmos basados en Inteligencia Artificial y aprendizaje no supervisado
con el fin de evaluar su efectividad. Tercero, analizar el desarrollo de aplicaciones de navegación autónoma drones
utilizando el simulador foto-realista Airsim junto con el middleware robóticos ROS empleando una arquitectura de
comunicación cliente-servidor. 

En conclusión, se comenta los objetivos que se han cumplido a lo largo del desarrollo como los requisitos cumplidos
que se expusieron en el capítulo 2, englobando líneas futuras dentro del trabajo. 

\section{Objetivos cumplidos}
\label{objetivos_cumplidos}

Los objetivos presentados en la sección \ref{sec:descripcion}, han sido cumplidos exitosamente 
\begin{enumerate}
    \item Se logró la instalación y configuración del simulador Airsim junto con ROS, estableciendo la comunicación efectiva
    entre dos equipos mediante protocolos de red. 
    \item Se implementó satisfactoriamente un sistema perceptivo capaz de realizar una detección del carril utilizando 
    redes neuronales junto con algoritmos de aprendizaje automático.
    \item Se implementó satisfactoriamente un sistema de control utilizando técnicas de aprendizaje por refuerzo, en especial Q-learning 
    para lograr el seguimiento del carril del dron de manera robusta y eficaz.
    \item Se completó de manera exitosa la aplicación para el seguimiento del carril para drones, haciendo uso del sistema perceptivo y de control
    \item Se han completado análisis efectivos para tanto para el sistema perceptivo como los comportamientos de control de PID y Q-learning, demostrando que el comportamiento
    de Q-learning es capaz de generalizar mejor en comparación con el controlador PID.
\end{enumerate}

\section{Requisitos satisfechos}
\label{requisitos_satisfechos}

En la sección \ref{sec:requisitos} se presentaron los requisitos que ha tenido este TFG, que se han ido resolviendo 
de la siguiente forma: 

\begin{enumerate}
    \item Durante todo el proceso del trabajo se utiliza Airsim junto con Unreal Engine como entorno de simulador.
    \item Los comportamientos desarrollados durante el trabajo se ha utilizado la estructura de ROS junto con la comunicación
    del entorno de simulación Airsim. 
    \item La navegación autónoma basada en aprendizaje por refuerzo ha demostrado ser lo suficiente robusta y eficiente en los
    diferentes trayectos dentro del escenario Coastline. 
    \item El comportamiento Q-learning junto con el sistema perceptivo han demostrado ser reactivos y poder reaccionar al entorno en tiempo real
    durante la navegación del dron.
    \item Uso del algoritmo de Q-Learning para desarrollar el comportamiento sigue-carril basados en aprendizaje por 
    refuerzo.
\end{enumerate}


\section{Balance global y competencias adquiridas}
\label{balance_global_competencias_adquiridas}
Durante el desarrollo de este TFG, el desafío de implementar una aplicación de navegación autónoma de drones basada en
aprendizaje por refuerzo y uso de redes neuronales resultó ser un proceso complejo y enriquecedor. Además de que la
combinación de aprendizaje por refuerzo e Inteligencia Artificial es una estrategia viable y efectiva para la
navegación autónoma de drones. Los resultados obtenidos son prometedores y sugieren que, con más investigación y
desarrollo, estos sistemas pueden ofrecer soluciones robustas y eficientes para la navegación autónoma en una variedad
de entornos sumando la arquitectura de conexión que se llego a implementar para ello. 

Al comienzo de este trabajo apenas tenía suficientes conocimientos básicos sobre Inteligencia Artificial enfocada en
redes neuronales y aprendizaje por refuerzo. Destacando que ha sido mi primer trabajo de investigación en donde he
aprendido múltiples conceptos, así como adquirir técnicas de análisis de errores que han ido apareciendo durante todo
el proceso. Destacando las siguientes competencias: 

\begin{itemize}
    \item Organización en cuanto a tiempos y tareas utilizando la metodología Kanban.
    \item Nuevos conocimientos en la utilización de simuladores robóticos.
    \item Nuevos conocimientos dentro del área de Inteligencia Artificial, así como redes neuronales y algoritmos de
    aprendizaje no supervisado. 
    \item Nuevos conocimientos desde cero sobre comportamientos basados en aprendizaje por refuerzo.
    \item Capacidad de analizar diferentes resultados recogidos en los diferentes comportamientos implementados.
    \item Mejora en la capacidad de implementar una arquitectura distribuida entre ambos equipos.
    \item Nuevos conocimientos sobre la integración de ROS junto con aplicaciones externas.
    \item Capacidad de documentación a la hora de desarrollar los diferentes comportamientos. 
\end{itemize}

\section{Líneas futuras}
\label{lineas_futuras}
Hemos obtenido resultados exitosos y satisfactorios a lo largo del TFG, dentro del campo de la navegación autónoma de drones, no obstante, existen diferentes líneas futuras que se
podrían desarrollar a partir de este trabajo.

\begin{itemize}
\item Re-entrenar la red YOLOP con un nuevo dataset teniendo en cuenta la posición y el ángulo de la cámara abordo del dron en diferentes entornos de Airsim.
\item Búsqueda de algoritmos alternativos que produzcan mejores resultados a la hora de refinar resultados de redes neuronales de segmentación.
\item Búsqueda sobre la infraestructura que existe entre el simulador PX4 Autopilot y Airsim, para tener mejores
comportamientos en cuanto a rendimiento y latencia.
\item Mejorar los sistemas de seguimiento de carril de aprendizaje por refuerzo sin las propias limitaciones que puede
presentar el algoritmo de Q-learning, usando algoritmos de Deep Reinforcement Learning.
\item Probar el comportamiento en diferentes escenarios distintos, con circuitos con curvas más cerradas, con situaciones de tiempo
adversas. 
\end{itemize}